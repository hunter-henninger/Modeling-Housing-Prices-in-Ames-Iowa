{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "This notebook seeks to optimize the benchmark model by implimenting ridge, lasso, and elastic net regularizations. After creating new second degree features, scaling, and transforming the data, I compare R-squared scores to choose the most predictive model. Using my best model I will predict house prices in Ames, Iowa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### External Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler , PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score , train_test_split , KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Cleaned and Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/preprocessed_train.csv')\n",
    "df_test = pd.read_csv('../datasets/preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get same interesting features list\n",
    "\n",
    "interesting_features = ['neighborhood','overall_qual', 'year_built', 'year_remod/add', 'exterior_1st',\n",
    "                        'mas_vnr_type', 'exter_qual', 'bsmt_qual', 'total_bsmt_sf', 'gr_liv_area',\n",
    "                        'full_bath', 'kitchen_qual', 'fireplaces', 'garage_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[interesting_features]\n",
    "Xtest = df_test[interesting_features]\n",
    "y = df_train['saleprice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y , test_size = 0.3 , random_state = 77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data to Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run poly features to create interaction terms with degree of 2\n",
    "# make sure to transform on both train and test\n",
    "\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "Xtest = poly.fit_transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale each feature using standard scaler \n",
    "\n",
    "ss = StandardScaler()  \n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "Xtest_sc = ss.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Four Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression produces an average R-squared of 0.8946040760380514.\n",
      "Lasso regression produces an average R-squared of 0.9022888169099292.\n",
      "Ridge regression produces an average R-squared of 0.9038493250636682.\n",
      "Elastic net regression produces an average R-squared of 0.9022888169099292.\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lasso = LassoCV() \n",
    "ridge = RidgeCV()\n",
    "en = ElasticNetCV(l1_ratio = [.1 , .5 , .7 , .9 , .95 , .99 , 1])\n",
    "\n",
    "# include a shuffled KFold with 10 splits to emphasize the accuracy of the cross-validation scores\n",
    "kf = KFold(n_splits = 10 , shuffle = True , random_state = 77)\n",
    "\n",
    "lr_cv = cross_val_score(lr, X_train_sc, y_train, cv=kf).mean()\n",
    "lasso_cv = cross_val_score(lasso, X_train_sc, y_train, cv=kf).mean()\n",
    "ridge_cv = cross_val_score(ridge, X_train_sc, y_train, cv=kf).mean()\n",
    "en_cv = cross_val_score(en, X_train_sc, y_train, cv=kf).mean()\n",
    "\n",
    "print('Linear regression produces an average R-squared of {}.' .format(lr_cv))\n",
    "print('Lasso regression produces an average R-squared of {}.' .format(lasso_cv))\n",
    "print('Ridge regression produces an average R-squared of {}.' .format(ridge_cv))\n",
    "print('Elastic net regression produces an average R-squared of {}.' .format(en_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing each of the cross-validation scores allows me to identify the best model for predicting house prices. The ridge regression produces the highest score which implies that shrinking the coefficients for select features improves the overall explanatory power of the model. However, because the scores are so similar, using lasso eliminates coefficients and allows for a more interpretable model, therefore I will make predictions using lasso. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression with the testing data produces a mean R-squared score of 0.9038493250636682.\n"
     ]
    }
   ],
   "source": [
    "# fit a lasso regression model on testing set\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X_test_sc, y_test, cv=kf).mean()\n",
    "print('Lasso regression with the testing data produces a mean R-squared score of {}.' .format(ridge_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared score for my testing set is nearly identical to the score for my training set. This means my model is neither overfit nor overfit.\n",
    "<br><br>\n",
    "In conclusion, performing a lasso regression on my interesting features is my best model. It produces the best balance between high explanatory power of sales price and most accessible interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create predictions for the test dataset for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_train_sc , y_train)\n",
    "\n",
    "y_hat = ridge.predict(Xtest_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2658</td>\n",
       "      <td>117423.253573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2718</td>\n",
       "      <td>178049.606242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2414</td>\n",
       "      <td>182514.148095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>114576.841390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>186818.688282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  2658  117423.253573\n",
       "1  2718  178049.606242\n",
       "2  2414  182514.148095\n",
       "3  1989  114576.841390\n",
       "4   625  186818.688282"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame([] , columns = ['Id' , 'SalePrice'])\n",
    "predictions['Id'] = df_test['id']\n",
    "predictions['SalePrice'] = y_hat\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions.csv for kaggle\n",
    "\n",
    "predictions.to_csv('../datasets/predictions.csv' , index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
